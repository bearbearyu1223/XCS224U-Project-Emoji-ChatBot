{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /opt/anaconda3/envs/nlu/lib/python3.8/site-packages (0.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji \n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Im so sorry about Rick Ross\"  üòÇ\n"
     ]
    }
   ],
   "source": [
    "# Notional example to use Python \"emoji\" library \n",
    "print(emoji.emojize('\"Im so sorry about Rick Ross\"  :face_with_tears_of_joy:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset \n",
    "\n",
    "* Raw dataset can be downloaded from Kaggle : https://www.kaggle.com/rexhaif/emojifydata-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweet_emoji_train_200000.csv', '.DS_Store', 'dev.txt', 'train.txt', 'emojitweets-01-04-2018.txt', 'test.txt']\n"
     ]
    }
   ],
   "source": [
    "# List the raw data in the directory \"data\"\n",
    "print(os.listdir('./data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line0: <START> O\n",
      "Line1: No O\n",
      "Line2: object O\n",
      "Line3: is O\n",
      "Line4: so O\n",
      "Line5: beautiful O\n",
      "Line6: that O\n",
      "Line7: under O\n",
      "Line8: certain O\n",
      "Line9: conditions O\n",
      "Line10: it O\n",
      "Line11: will O\n",
      "Line12: not O\n",
      "Line13: look O\n",
      "Line14: ugly O\n",
      "Line15: Oscar O\n",
      "Line16: Wilde O\n",
      "Line17: ‚Ü∫ O\n",
      "Line18: RT :red_heart:\n",
      "Line19: ‚Ä¶ O\n",
      "Line20: <STOP> O\n",
      "Line21: \n",
      "Line22: <START> O\n",
      "Line23: Cant O\n",
      "Line24: expect O\n",
      "Line25: different O\n",
      "Line26: results O\n",
      "Line27: doing O\n",
      "Line28: the O\n",
      "Line29: same O\n",
      "Line30: thingdoing O\n",
      "Line31: stuff O\n",
      "Line32: different O\n",
      "Line33: from O\n",
      "Line34: now O\n",
      "Line35: on :person_shrugging:\n",
      "Line36: üèª O\n",
      "Line37: ‚Äç :female_sign:\n",
      "Line38: Ô∏è O\n",
      "Line39: <STOP> O\n"
     ]
    }
   ],
   "source": [
    "# Explore the format of the raw data\n",
    "dev_data_raw = open('./data/dev.txt', 'r') \n",
    "dev_data_lines = dev_data_raw.readlines() \n",
    "\n",
    "train_data_raw = open('./data/train.txt', 'r') \n",
    "train_data_lines = train_data_raw.readlines() \n",
    "\n",
    "test_data_raw = open('./data/test.txt', 'r') \n",
    "test_data_lines = test_data_raw.readlines() \n",
    "\n",
    "count = 0\n",
    "for line in dev_data_lines[0:40]: \n",
    "    print(\"Line{}: {}\".format(count, str(line.strip())))\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few helper functions to parse the raw data and create dataset for dev, train, and test\n",
    "def get_emoji(tweet:List[str])->List[str]:\n",
    "    s = ' '.join(tweet)\n",
    "    if re.findall(r':(.*?):', s):\n",
    "        return re.findall(r':(.*?):', s)\n",
    "\n",
    "def remove_emoji(tweet:List[str])->List[str]:\n",
    "    s = ' '.join(tweet)\n",
    "    if re.findall(r':(.*?):', s):\n",
    "        return re.sub(r':(.*?):','', s)\n",
    "    \n",
    "def creat_dataset(lines:List[str], sample_size:int=1000)->List[dict]:\n",
    "\n",
    "    samples = list()\n",
    "    id = 0\n",
    "    is_new_tweet = False\n",
    "\n",
    "    for line in lines:\n",
    "        if id < sample_size:\n",
    "            if '<START> O' in line:\n",
    "                is_new_tweet = True\n",
    "                sample = dict()\n",
    "                sample['id'] = id\n",
    "                sample['tweet'] = list()\n",
    "                continue\n",
    "            elif '<STOP> O' in line:\n",
    "                sample['emoji']= get_emoji(sample['tweet'])\n",
    "                sample['tweet']= remove_emoji(sample['tweet'])\n",
    "                samples.append(sample)\n",
    "                id = id + 1\n",
    "                is_new_tweet = False\n",
    "            else:\n",
    "                _line = re.sub(r'[^a-zA-Z0-9_:-]+','', re.sub(r' O', '', line))\n",
    "                if _line != '':\n",
    "                    if is_new_tweet:\n",
    "                        sample['tweet'].append(_line)\n",
    "                    else:\n",
    "                        is_new_tweet = True\n",
    "                        sample = dict()\n",
    "                        sample['id'] = id\n",
    "                        sample['tweet'] = list()\n",
    "                        sample['tweet'].append(_line)\n",
    "    return samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few helper functions to parse the raw data and create dataset for dev, train, and test\n",
    "def get_emoji_set_from_tweet(tweet:str)->List[str]:\n",
    "    # ?: lazy match, stop at the first match.\n",
    "    return set(re.findall(r':(.+?):', tweet))\n",
    "\n",
    "def remove_emojis_from_tweet(tweet:str)->str:\n",
    "    return re.sub(r':(.+?):', '', tweet)\n",
    "\n",
    "def creat_dataset_v2(lines:List[str], sample_size:int=1000)->List[dict]:\n",
    "    \"\"\"Converts raw tweet format to a list of dict with id, tweet string, and emoji set as elements.\n",
    "    \n",
    "    Input:\n",
    "        <START> O\n",
    "        tweet\n",
    "        ...\n",
    "        :emoji:\n",
    "        ...\n",
    "        <STOP> O\n",
    "\n",
    "        <START> :emoji:\n",
    "        tweet\n",
    "        ...\n",
    "        <STOP> O\n",
    "    \n",
    "    Output:\n",
    "        [\n",
    "            {\n",
    "                id: 0\n",
    "                tweet: 'the tweet sting'\n",
    "                emoji: {:emoji_0:, :emoji_1:}\n",
    "            }\n",
    "        ]\n",
    "    \"\"\"\n",
    "    SEP = r' O'\n",
    "    datasets = list()\n",
    "    id = 0\n",
    "    tweet_words = list()\n",
    "    data = dict()\n",
    "        \n",
    "    for line in lines:\n",
    "        if id >= sample_size:\n",
    "            break\n",
    "        # Remove spacial characters and separator from line.\n",
    "        # \\w: [a-zA-Z0-9_]\n",
    "        _line = re.sub(r'[^\\w:-]+', '', re.sub(SEP, '', line)).strip()\n",
    "        if _line:\n",
    "            tweet_words.append(_line)\n",
    "        if '<STOP> O' in line:\n",
    "            # Remove empty charaters at the begining and end.\n",
    "            tweet = ' '.join(tweet_words).strip()\n",
    "            # Remove START and STOP string at the begining and end.\n",
    "            tweet = re.sub('^START\\s*', '', re.sub('\\s*STOP$', '', tweet))\n",
    "            data['id'] = id\n",
    "            data['tweet']= remove_emojis_from_tweet(tweet).strip()\n",
    "            data['emoji']= get_emoji_set_from_tweet(tweet)\n",
    "            datasets.append(data)\n",
    "            # Increase id and reset temporary vars.\n",
    "            id = id + 1\n",
    "            tweet_words = list()\n",
    "            data = dict()\n",
    "\n",
    "    return datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 800000\n",
    "train_dataset = creat_dataset_v2(train_data_lines, sample_size = sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_dataset)\n",
    "df_train.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CeeC is going to be another Tboss What is 45 million Naira</td>\n",
       "      <td>{face_with_tears_of_joy}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This gif kills me Death is literally gushing towards you and you really gon do a whole 3point turn</td>\n",
       "      <td>{weary_face}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOVE TEST Raw Real JaDine</td>\n",
       "      <td>{purple_heart}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i swear we dont gotta look it finds us</td>\n",
       "      <td>{face_with_tears_of_joy}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We would like to wish everyone a very Happy New Year and all the best in 2018</td>\n",
       "      <td>{party_popper}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 tweet  \\\n",
       "id                                                                                                       \n",
       "0                                           CeeC is going to be another Tboss What is 45 million Naira   \n",
       "1   This gif kills me Death is literally gushing towards you and you really gon do a whole 3point turn   \n",
       "2                                                                            LOVE TEST Raw Real JaDine   \n",
       "3                                                               i swear we dont gotta look it finds us   \n",
       "4                        We would like to wish everyone a very Happy New Year and all the best in 2018   \n",
       "\n",
       "                       emoji  \n",
       "id                            \n",
       "0   {face_with_tears_of_joy}  \n",
       "1               {weary_face}  \n",
       "2             {purple_heart}  \n",
       "3   {face_with_tears_of_joy}  \n",
       "4             {party_popper}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"./data/tweet_emoji_train_\" + str(sample_size) + '.csv'\n",
    "df_train.to_csv(csv_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
